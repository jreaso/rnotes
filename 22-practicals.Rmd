# Practicals (Temporary)

## Practical 1 {-}

```{r}
data(faithful)
w = faithful$waiting
d = faithful$eruptions

plot(d, w, col = "darkgrey", xlab = "Duration of Eruptions (m)", ylab = "Waiting Time (m)", main = "Faithful Geyser", bty = 'l', pch = 16)

cor(w, d) #Pearson correlation coefficient

model = lm(w ~ d)
coef(model)

beta0hat <- coef(model)[1]
beta1hat <- coef(model)[2]

lsq.Q = sum(resid(model)^2)

summary(model)
#coef estimates: w = 33.5 + 10.7 d
#coef std errors: 1.15 and 0.31 respectively
#residual std error: 5.914
#regression R^2: 0.8115
#t-value column is t-test associated with testing significance of params. as p-values are small, both parameters are significant

se = summary(model)$sigma

rsq <- summary(model)$r.squared
cor(w, d)^2

se.beta1 <- summary(model)$coefficients[2,2]
t.beta1 <- unname((beta1hat-0)/se.beta1)

n <- length(w)
#p-value
2*(1-pt(t.beta1, n-2)) # df = n-2

#Confidence Interval
beta1hat + c(-1,1) * qt(0.975,n-2) * se.beta1
confint(model, level = 0.95)

#confidence interval
predict(model, newdata = data.frame(d = 3), interval = "confidence", level = 0.95)
#prediction interval
predict(model, newdata = data.frame(d = 3), interval = "prediction", level = 0.95)

par(mfrow=c(1,2))
plot(y=resid(model), x=fitted(model), col="darkgrey", xlab="Fitted Values", ylab="Residuals", bty='l', pch=16)
plot(y=resid(model), x=d, col="darkgrey", xlab="Fitted Values", ylab="Duration of Eruptions (m)", bty='l', pch=16)

par(mfrow=c(1,2))
hist(resid(model))
qqnorm(resid(model))

par(mfrow=c(1,1))
```

## Practical 2 {-}

```{r}
library("faraway")
names(fat)
head(fat)
summary(fat)
sum(is.na(fat)) #no missing data

fat1 <- fat[,-c(2,3,8)] #removing 3 variables

dim(fat1)
pairs(fat1)

panel.cor <- function(x, y){
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- round(cor(x, y), digits=2)
  txt <- paste0(" ", r)
  text(0.5, 0.5, txt, cex = 0.8)
}
upper.panel<-function(x, y){
  points(x,y, pch = 20, col=2)
}
pairs(fat1, 
      lower.panel = panel.cor,
      upper.panel = upper.panel)

library(corrplot)
#corrplot(cor(fat1), method = "number", type = "upper", diag = FALSE)
corrplot.mixed(cor(fat1), upper = "ellipse", lower = "number",number.cex = .7)

reg1 <- lm(brozek~adipos,data=fat1)
summary(reg1)
names(reg1)
coef(reg1)

confint(reg1, level = 0.95)

predict(reg1, data.frame(adipos=22), interval="confidence",  level = 0.95)
predict(reg1, data.frame(adipos=22), interval="prediction",  level = 0.95)

plot(fat1$adipos, fat1$brozek, pch=16, col="cornflowerblue")
abline(reg1,lwd=3,col="red")

par(mfrow=c(1,2))
plot(reg1, which=1,  pch=16, col="cornflowerblue")
plot(reg1, which=2,  pch=16, col="cornflowerblue")
par(mfrow=c(1,1))

reg2 <- lm(brozek~adipos+age,data=fat1)
summary(reg2)

reg3 <- lm(brozek~.,data=fat1)
summary(reg3)

reg4 <- lm(brozek~.-age,data=fat1)
summary(reg4)

summary(reg1)$r.sq
summary(reg2)$r.sq
summary(reg3)$r.sq
summary(reg4)$r.sq

library(car)
vif(reg3)

summary(lm(brozek~chest*abdom, data=fat1))
summary(lm(brozek~adipos+I(adipos^2), data=fat1))
summary(lm(brozek~log(adipos), data=fat1))

library("leaps")
fwd = regsubsets(brozek~., data = fat1, method = 'forward', nvmax = 14)
results = summary(fwd)
results

RSS = results$rss
r2 = results$rsq
Cp = results$cp
BIC = results$bic
Adj_r2 = results$adjr2

criteria_values <- cbind(RSS, r2, Cp, BIC, Adj_r2)
criteria_values

which.min(Cp)
which.min(BIC)
which.max(Adj_r2)

coef(fwd, 4)
coef(fwd, 8)

par(mfrow = c(1, 3))
plot(Cp, xlab = "Number of Predictors", ylab = "Cp", type = 'l', lwd = 2)
points(8, Cp[8], col = "red", cex = 2, pch = 8, lwd = 2)
plot(BIC, xlab = "Number of Predictors", ylab = "BIC", type = 'l', lwd = 2)
points(4, BIC[4], col = "red", cex = 2, pch = 8, lwd = 2)
plot(Adj_r2, xlab = "Number of Predictors", ylab = "Adjusted RSq", 
     type = "l", lwd = 2)
points(8, Adj_r2[8],  col = "red", cex = 2, pch = 8, lwd = 2)

par(mfrow=c(1,1))

plot(fwd, scale = "Cp")

best = regsubsets(brozek~., data = fat1, nvmax = 14)
bwd = regsubsets(brozek~., data = fat1, method = 'backward', nvmax = 14)

which.min(summary(best)$cp)
which.min(summary(best)$bic)
which.max(summary(best)$adjr2)
which.min(summary(bwd)$cp)
which.min(summary(bwd)$bic)
which.max(summary(bwd)$adjr2)

coef(fwd,8) 
coef(best,8) 
coef(bwd,8)

coef(fwd,4) 
coef(best,4) 
coef(bwd,4)
```

## Practical 3 {-}

```{r}
library(faraway)
?seatpos

dim(seatpos)
sum(is.na(seatpos))
cor(seatpos[,9], seatpos[,-9])
cor( seatpos[,-9] )
pairs( seatpos, pch = 16, col = 2 )

y = seatpos$hipcenter
x = model.matrix(hipcenter~., seatpos)[,-1]

library("glmnet")
ridge = glmnet(x, y, alpha = 0, nlambda = 200)
plot(ridge, xvar = 'lambda')

lasso = glmnet(x, y)
par(mfrow = c(1,2))
plot(lasso, xvar = 'lambda')
plot(lasso)

par(mfrow=c(1,1))

lasso$lambda
lasso$beta

s <- apply(x, 2, sd)       # calculates the column standard deviations
x.s  <- sweep(x, 2, s, "/")  # divides all columns by their standard deviations
seatpos.pr <- prcomp(x.s)

seatpos.pr
seatpos.pr$rotation[,1]
plot(seatpos.pr)
summary(seatpos.pr)

T   <- t(seatpos.pr$x[,c(1,2,3,4)])  #compressed using 4 PCs
ms <- colMeans(x.s) 
R   <- t(ms + seatpos.pr$rot[,c(1,2,3,4)]%*% T) #reconstruction 
plot(rbind(x.s[,1:2], R[,1:2]), pch=20, bty='l',col=c(rep(2,38),rep(4,38))) 

library("pls")
pcr.fit=pcr(hipcenter~., data=seatpos, scale = TRUE, validation = "CV" )
summary(pcr.fit)

validationplot( pcr.fit, val.type = 'MSEP' )
coef(pcr.fit, ncomp = 2)

library(leaps)

predict.regsubsets = function(object, newdata, id, ...){
  form = as.formula(object$call[[2]])
  mat = model.matrix(form, newdata)
  coefi = coef(object, id = id)
  xvars = names(coefi)
  mat[, xvars]%*%coefi
}

repetitions = 100
cor.bss = c()
cor.ridge = c()
cor.lasso = c()
cor.pcr = c()

set.seed(1)                
for(i in 1:repetitions){
  # Step (i) data splitting
  training.obs = sample(1:38,  28)
  y.train = seatpos$hipcenter[training.obs]
  x.train = model.matrix(hipcenter~., seatpos[training.obs, ])[,-1]
  y.test = seatpos$hipcenter[-training.obs]
  x.test = model.matrix(hipcenter~., seatpos[-training.obs, ])[,-1]
  
  # Step (ii) training phase
  bss.train = regsubsets(hipcenter~., data=seatpos[training.obs,], nvmax=8)
  min.cp = which.min(summary(bss.train)$cp)
  ridge.train = cv.glmnet(x.train, y.train, alpha = 0, nfolds = 5)
  lasso.train = cv.glmnet(x.train, y.train, nfold = 5)
  pcr.train = pcr(hipcenter~., data =seatpos[training.obs,], 
                  scale = TRUE, validation="CV")
  min.pcr = which.min(MSEP(pcr.train)$val[1,1, ] ) - 1
  
  # Step (iii) generating predictions
  predict.bss = predict.regsubsets(bss.train, seatpos[-training.obs, ], min.cp)
  predict.ridge = predict(ridge.train, x.test, s = 'lambda.min')
  predict.lasso = predict(lasso.train, x.test, s = 'lambda.min')
  predict.pcr = predict(pcr.train,seatpos[-training.obs, ], ncomp = min.pcr )
  
  # Step (iv) evaluating predictive performance
  cor.bss[i] = cor(y.test, predict.bss)
  cor.ridge[i] = cor(y.test, predict.ridge)
  cor.lasso[i] = cor(y.test, predict.lasso)
  cor.pcr[i] = cor(y.test, predict.pcr)
}

# Plot the resulting correlations as boxplots.
boxplot(cor.bss, cor.ridge, cor.lasso, cor.pcr, 
        names = c('BSS','Ridge', 'Lasso', 'PCR'), 
        ylab = 'Test correlation', col = 2:5)
```

## Practical 4 {-}

```{r}
library("MASS")
library("faraway")

y = seatpos$hipcenter
x = seatpos$Ht
y.lab = 'hip center (mm)'
x.lab = 'Height (bare foot) in cm'
plot( x, y, cex.lab = 1.1, col="darkgrey", xlab = x.lab, ylab = y.lab, 
      main = "", bty = 'l', pch = 16 )

poly1 = lm(y ~ poly(x,  1))
summary(poly1)

poly2 = lm(y ~ poly(x,  2))
summary(poly2)

grid = seq(min(x), max(x), length.out = 1000) 

pred1 = predict(poly1, newdata = list(x = grid), se = TRUE)
pred2 = predict(poly2, newdata = list(x = grid), se = TRUE)

# Confidence interval bands.
se.bands1 = cbind( pred1$fit - 2*pred1$se.fit, pred1$fit + 2*pred1$se.fit )
se.bands2 = cbind( pred2$fit - 2*pred2$se.fit, pred2$fit + 2*pred2$se.fit )

# Plot both plots on a single graphics device.
par(mfrow = c(1,2))

# Degree-1 polynomial plot.
plot(x, y, cex.lab = 1.1, col="darkgrey", xlab = x.lab, ylab = y.lab,
     main = "Degree-1 polynomial", bty = 'l', pch=20)
lines(grid, pred1$fit, lwd = 2, col = "red")
matlines(grid, se.bands1, lwd = 2, col = "red", lty = 3)

# Degree-2 polynomial plot.
plot(x, y, cex.lab = 1.1, col="darkgrey", xlab = x.lab, ylab = y.lab,
     main = "Degree-2 polynomial", bty = 'l', pch=20)
lines(grid, pred2$fit, lwd = 2, col = "red")
matlines(grid, se.bands2, lwd = 2, col = "red", lty = 3)

par(mfrow=c(1,1))

step6 = lm(y ~ cut(x, 6))
pred6 = predict(step6, newdata = list(x = grid), se = TRUE)
se.bands6 = cbind(pred6$fit + 2*pred6$se.fit, pred6$fit-2*pred6$se.fit)

# Plot the results.
plot(x, y, cex.lab = 1.1, col="darkgrey", xlab = x.lab, ylab = y.lab,
     main = "5 cutpoints", bty = 'l', pch=16)
lines(grid, pred6$fit, lwd = 2, col = "red")
matlines(grid, se.bands6, lwd = 1.4, col = "red", lty = 3)

summary(step6)

summary(x)
cuts <- summary(x)[c(2,3,5)]

library("splines")
spline1 = lm(y ~ bs(x, degree = 1, knots = cuts))

grid.x = seq(min(x), max(x), length.out = 100) 

pred1 = predict(spline1, newdata = list(x = grid.x), se = TRUE)
se.bands1 = cbind(pred1$fit + 2 * pred1$se.fit, pred1$fit - 2 * pred1$se.fit)

plot(x, y, cex.lab = 1.1, col="darkgrey", xlab = x.lab, ylab = y.lab, 
     main = "Linear Spline", bty = 'l', pch = 16)
lines(grid.x, pred1$fit, lwd = 2, col = "red")
matlines(grid.x, se.bands1, lwd = 2, col = "red", lty = 3)

smooth1 = smooth.spline(x, y, df = 3)

plot(x, y, cex.lab = 1.1, col="darkgrey", xlab = x.lab, ylab = y.lab, 
     main = "Smoothing Spline (3df)", bty = 'l', pch=16)
lines(smooth1, lwd = 2, col = "brown")

library(gam)

gam = gam( hipcenter ~ ns( Age, df = 5 ) + s( Thigh, df = 3 ) + Ht, 
           data = seatpos )

par( mfrow = c(2,3) )
plot( gam,  se = TRUE, col = "blue" )
plot( seatpos$Age, seatpos$hipcenter, pch = 16, col = 2, 
      ylab = y.lab, xlab = "Age (years)" )
plot( seatpos$Thigh, seatpos$hipcenter, pch = 16, col = 2, 
      ylab = y.lab, xlab = "Thigh length (cm)" )
plot( seatpos$Ht, seatpos$hipcenter, pch = 16, col = 2, 
      ylab = y.lab, xlab = "Ht (bare foot) (cm)" )

par(mfrow=c(1,1))

library("MASS")
library(splines)

y = Boston$medv
x = Boston$indus
y.lab = 'Median Property Value'
x.lab = 'Non-retail business acres per town'

summary(x)

cuts <- summary(x)[c(2,3,5)]
cuts

grid.x = seq(min(x), max(x), length.out = 100)

# Fit a cubic spline
spline.bs = lm(y ~ bs(x, knots = cuts))
pred.bs = predict(spline.bs, newdata = list(x = grid.x), se = TRUE)
se.bands.bs = cbind(pred.bs$fit + 2 * pred.bs$se.fit, 
                    pred.bs$fit - 2 * pred.bs$se.fit)

# Fit a natural cubic spline.
spline.ns = lm(y ~ ns(x, knots = cuts))
pred.ns = predict(spline.ns, newdata = list(x = grid.x), se = TRUE)
se.bands.ns = cbind(pred.ns$fit + 2 * pred.ns$se.fit, 
                    pred.ns$fit - 2 * pred.ns$se.fit)

# Fit a smoothing spline, with 3 effective degrees of freedom.
spline.smooth = smooth.spline(x, y, df = 3)

# Split the plotting device into 3.
par(mfrow = c(1,3))

# Plot the cubic spline.
plot(x, y, cex.lab = 1.1, col="darkgrey", xlab = x.lab, ylab = y.lab, 
     main = "Cubic Spline", bty = 'l')
lines(grid.x, pred.bs$fit, lwd = 2, col = "red")
matlines(grid.x, se.bands.bs, lwd = 2, col = "red", lty = 3)

# Plot the natural cubic spline.
plot(x, y, cex.lab = 1.1, col="darkgrey", xlab = x.lab, ylab = y.lab, 
     main = "Natural Cubic Spline", bty = 'l')
lines(grid.x, pred.ns$fit, lwd = 2, col = "darkred")
matlines(grid.x, se.bands.ns, lwd = 2, col = "darkred", lty = 3)

# Plot the smoothing spline.
plot(x, y, cex.lab = 1.1, col="darkgrey", xlab = x.lab, ylab = y.lab, 
     main = "Smoothing Spline (3 df)", bty = 'l')
lines(spline.smooth, lwd = 2, col = "brown")

Boston1 = Boston
Boston1$chas = factor(Boston1$chas)

gam1 = gam( medv ~ ns( lstat, df = 5 ) + ns( nox, df = 7 ) + 
              s( indus, df = 7 ) + poly( age, 5 ) + chas, data = Boston1 )
par(mfrow = c(2,3))
plot(gam1,  se = TRUE, col = "blue")


admit <- read.csv("https://www.maths.dur.ac.uk/users/hailiang.du/data/admit.csv")
head(admit)
summary(admit)

pairs(admit[,2:4], col=admit[,1]+2, pch=20)

admit$rank <- factor(admit$rank)
glm.fit = glm(admit ~ ., data=admit, family="binomial")
summary(glm.fit)

glm.probs <- predict(glm.fit, type = "response")
glm.probs[1:10]

glm.pred=rep(0, 400)
glm.pred[glm.probs > .5] = 1

table(glm.pred, admit$admit)
(254 + 30) / 400

mean(glm.pred == admit$admit)
```
